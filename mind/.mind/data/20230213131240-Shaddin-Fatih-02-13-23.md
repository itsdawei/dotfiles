# Shaddin-Fatih 02/13/23

## Axioms

- According to QD, **(strictly) monotonicity** should be required.
  - Goal was to find a solution point at **every** point in the space (does
    this make sense?).
    > We should not be penalized for not exploring "bad" solutions in the search
    > space.

### Working Axioms

1. $div(\phi) = div(\{x\}) = 0$
1. Scale-invariance: The optimal set does not change if you scale the distance
   function and the objective function
1. Consistency
1. Richness
1. Stability: the optimal set does not change arbitrarily with the output size.
1. Independence of Irrelevant Attributes (IIA)
1. Monotone

## Diversity Score

> When the score is defined individual points in $S$. The diversity of the
> entire set is the sum over all members.

**Distance to $k$-NN**:
Let $N_k(s)$ be the set of $k$-nearest neighbors to $s \in S$.

$$
\mathrm{NN}_k(S) = \sum_{s \in S}\sum_{s' \in N_k(s)} d(s, s')
$$

Consider $S = \{x_1, \dots, x_n\}$ where $n > k \ge 1$ (i.e., there exists $k
\ge 1$ nearest neighbors for all $x_i$) and $d(x_i, x_j) = 2$ for $i \ne j$.

We have $\mathrm{NN}_k(S) = 2nk$ for each point contributes 2 units for each of its $k$
nearest neighbors.
However, consider $S' = S \cup \{x'\}$ where $d(x', x_i) = 1 + \epsilon$ for $x_i \in S$,
we have

$$
\begin{aligned}
\mathrm{NN}_k(S') &= (2(k-1) + (1 + \epsilon))n + (1 + \epsilon)k \\
                  &= 2nk - 2n + (1 + \epsilon)n + (1 + \epsilon)k \\
                  &= \mathrm{NN}_k(S) - 2n + (1 + \epsilon)n + (1 + \epsilon)k \\
                  &= \mathrm{NN}_k(S) - (1 - \epsilon)n + (1 + \epsilon)k
\end{aligned}
$$

Thus, we have

$$
\mathrm{NN}_k(S) > \mathrm{NN}_k(S') \iff (1 - \epsilon)n > (1 + \epsilon)k
$$

For sufficiently small $\epsilon$, the above is true when $n > k$.
Since we assumed $n > k \ge 1$, we have $\mathrm{NN}_k(S) > \mathrm{NN}_k(S')$
for sufficiently small $\epsilon$.
Thus, distance to $k$-nearest neighbor is **violates monotonicity**.

**Average Distance to $k$-NN (novelty score)**:
Let $N_k(s)$ be the k-NN to $s \in S$.

$$
\mathrm{NS}_k(S) = \frac{1}{k} \sum_{s \in S} \sum_{s' \in N_k(s)} d(s, s') \\
      = \frac{1}{k} \mathrm{NN}_k(S)
$$

Consider the same construction as above, where we have $S = \{x_1, \dots,
x_n\}$ and $S' = S \cup \{x'\}$, we have

$$
\mathrm{NN}_k(S) > \mathrm{NN}_k(S') \\
\frac{1}{k} \mathrm{NN}_k(S) > \frac{1}{k} \mathrm{NN}_k(S')
$$

By a similar argument, average distance to $k$-NN (i.e., novelty score)
**violates monotonicity**.

---

- Diameter of the set $S$
- Average distance between all pairs of points in $S$
- Volume of the convex hull of $S$
- Minimum (or average) over all points $x \in S$ of the distance from $x$ to $S
  \setminus x$.
- Affine transformation on space and distance function.

- What if we average the score by $\frac{1}{n}$, i.e., average over all members
  of the solution set?

## Literatures

- [KDE](/home/dawei/.mind/data/20230213130435-KDE.md) and
  [DPP](/home/dawei/.mind/data/20230213132137-DPP.md)
- Re-ranking top-$k$ documents.
  - Only requires definition of diversity for each document.
  - Similar to novelty search.
  - Implicitly greedy approach?
- Address the **one-way** nature of the measure functions; our combinatorics
  approach seems sound.
  - Doesn't require sampling on the measure space. In practice, just sample on
    solution space $K$ times and get the objective and measure space
    coordinates.
  - Alternative approaches, like directly sampling on the objective function,
    doesn't really work.
  - We should keep this limitation in mind.
